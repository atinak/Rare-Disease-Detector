{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e7DmrkmyczTs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class OrphanetDataProcessor:\n",
    "\n",
    "    def __init__(self, data_dir: str = \"../data\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_df = None\n",
    "        self.hpo_features = None\n",
    "        self.disability_features = None\n",
    "        self.prevalence_features = None\n",
    "        self.inheritance_features = None\n",
    "        self.age_of_onset_features = None\n",
    "\n",
    "        self.frequency_mapping = {\n",
    "            \"Very frequent (99-80%)\": 0.9,\n",
    "            \"Frequent (79-30%)\": 0.5,\n",
    "            \"Occasional (29-5%)\": 0.15,\n",
    "            \"Very rare (<5%)\": 0.025,\n",
    "            \"Excluded (0%)\": 0.0,\n",
    "            \"\": 0.0,  # Handle empty values\n",
    "            \"N/A\": 0.0 # Handle N/A\n",
    "        }\n",
    "\n",
    "        # Create data directory if it doesn't exist\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    def _safe_json_loads(self, json_string: str) -> Union[Dict, List, None]:\n",
    "        \"\"\"Safely loads potentially malformed JSON strings.\"\"\"\n",
    "        try:\n",
    "            return json.loads(json_string)\n",
    "        except Exception as e:  # Catch *any* exception during JSON parsing\n",
    "            logger.warning(f\"Invalid JSON encountered: {json_string}, error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def load_data(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"Loads data from a CSV file.\"\"\"\n",
    "        full_path = os.path.join(self.data_dir, file_path)\n",
    "        logger.info(f\"Loading data from {full_path}\")\n",
    "        try:\n",
    "            self.data_df = pd.read_csv(full_path)\n",
    "            #CRITICAL: Replace 'N/A' strings with actual NaN *before* doing anything\n",
    "            self.data_df = self.data_df.replace('N/A', pd.NA)\n",
    "            logger.info(f\"Loaded {len(self.data_df)} records\")\n",
    "            return self.data_df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def parse_hpo_associations(self) -> pd.DataFrame:\n",
    "        \"\"\"Parses HPO associations from the HPODisorderAssociation_df2 column.\"\"\"\n",
    "        if self.data_df is None:\n",
    "            raise ValueError(\"Data not loaded. Call load_data() first.\")\n",
    "\n",
    "        logger.info(\"Parsing HPO associations\")\n",
    "        hpo_data = []\n",
    "\n",
    "        for idx, row in self.data_df.iterrows():\n",
    "            orpha_code = row['OrphaCode']\n",
    "            disease_name = row['Name']\n",
    "            # Use .get() with a default empty string\n",
    "            hpo_list = self._safe_json_loads(row.get('HPODisorderAssociation_df2', '[]'))\n",
    "            if hpo_list is None:\n",
    "                continue\n",
    "\n",
    "            for hpo_item in hpo_list:\n",
    "                hpo_data.append({\n",
    "                    'OrphaCode': orpha_code,\n",
    "                    'DiseaseName': disease_name,\n",
    "                    'HPOId': hpo_item.get('HPOId', ''),\n",
    "                    'HPOTerm': hpo_item.get('HPOTerm', ''),\n",
    "                    'HPOFrequency': hpo_item.get('HPOFrequency', ''),\n",
    "                    'HPOFrequencyValue': self.frequency_mapping.get(hpo_item.get('HPOFrequency', ''), 0.0),\n",
    "                    'DiagnosticCriteria': hpo_item.get('DiagnosticCriteria', '')\n",
    "                })\n",
    "        hpo_df = pd.DataFrame(hpo_data)\n",
    "        logger.info(f\"Extracted {len(hpo_df)} HPO associations\")\n",
    "        return hpo_df\n",
    "\n",
    "    def create_hpo_feature_matrix(self, hpo_df: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "        \"\"\"Creates a feature matrix where each row is a disease and columns are HPO terms.\"\"\"\n",
    "        if hpo_df is None:\n",
    "            hpo_df = self.parse_hpo_associations()\n",
    "\n",
    "        logger.info(\"Creating HPO feature matrix\")\n",
    "\n",
    "        # Ensure OrphaCode is string type BEFORE pivoting\n",
    "        hpo_df['OrphaCode'] = hpo_df['OrphaCode'].astype(str)\n",
    "\n",
    "        feature_matrix = hpo_df.pivot_table(\n",
    "            index=['OrphaCode', 'DiseaseName'],\n",
    "            columns='HPOId',\n",
    "            values='HPOFrequencyValue',\n",
    "            fill_value=0\n",
    "        )\n",
    "        feature_matrix = feature_matrix.reset_index()\n",
    "        self.hpo_features = feature_matrix\n",
    "        logger.info(f\"Created feature matrix with {feature_matrix.shape[1]-2} HPO features\")\n",
    "        return feature_matrix\n",
    "\n",
    "    def get_hpo_term_mapping(self, hpo_df: Optional[pd.DataFrame] = None) -> Dict[str, str]:\n",
    "        \"\"\"Creates a mapping from HPO IDs to HPO terms.\"\"\"\n",
    "        if hpo_df is None:\n",
    "            hpo_df = self.parse_hpo_associations()\n",
    "        hpo_mapping = hpo_df[['HPOId', 'HPOTerm']].drop_duplicates()\n",
    "        hpo_dict = dict(zip(hpo_mapping['HPOId'], hpo_mapping['HPOTerm']))\n",
    "        return hpo_dict\n",
    "\n",
    "    def parse_disability_associations(self) -> pd.DataFrame:\n",
    "        if self.data_df is None:\n",
    "          raise ValueError(\"Data not loaded. Call load_data() first.\")\n",
    "\n",
    "        logger.info(\"Parsing disability associations\")\n",
    "        disability_data = []\n",
    "\n",
    "        for idx, row in self.data_df.iterrows():\n",
    "          orpha_code = row['OrphaCode']\n",
    "          disease_name = row['Name']\n",
    "\n",
    "          for col_num in range(3, 6):  # Columns df3, df4, and df5\n",
    "              col_name = f'DisabilityDisorderAssociations_df{col_num}'\n",
    "              # Use .get() to handle missing columns gracefully.\n",
    "              disability_list = self._safe_json_loads(row.get(col_name, '[]'))\n",
    "              if disability_list is None:\n",
    "                  continue\n",
    "\n",
    "              for disability_item in disability_list:\n",
    "                  disability_data.append({\n",
    "                      'OrphaCode': orpha_code,\n",
    "                      'DiseaseName': disease_name,\n",
    "                      'Disability': disability_item.get('Disability', ''),\n",
    "                      'FrequencyDisability': disability_item.get('FrequencyDisability', ''),\n",
    "                      'FrequencyDisabilityValue': self.frequency_mapping.get(disability_item.get('FrequencyDisability', ''), 0.0),\n",
    "                      'TemporalityDisability': disability_item.get('TemporalityDisability', ''),\n",
    "                      'SeverityDisability': disability_item.get('SeverityDisability', ''),\n",
    "                      'LossOfAbility': disability_item.get('LossOfAbility', ''),\n",
    "                      'TypeDisability': disability_item.get('TypeDisability', ''),\n",
    "                      'Defined': disability_item.get('Defined', '')\n",
    "                    })\n",
    "        disability_df = pd.DataFrame(disability_data)\n",
    "        logger.info(f\"Extracted {len(disability_df)} disability associations\")\n",
    "        return disability_df\n",
    "    def parse_average_age_of_onset(self) -> pd.DataFrame:\n",
    "        if self.data_df is None:\n",
    "          raise ValueError(\"Data not loaded.  Call load_data() first.\")\n",
    "        logger.info(\"Parsing average age of onset\")\n",
    "        age_of_onset_data = []\n",
    "\n",
    "        for idx, row in self.data_df.iterrows():\n",
    "            orpha_code = row['OrphaCode']\n",
    "            disease_name = row['Name']\n",
    "            for col_num in range(4, 6):  # Columns df4 and df5\n",
    "                col_name = f'AverageAgesOfOnset_df{col_num}'\n",
    "                # Use .get() to handle missing columns gracefully\n",
    "                age_of_onset_list = self._safe_json_loads(row.get(col_name, '[]'))\n",
    "                if age_of_onset_list is None:\n",
    "                    continue\n",
    "\n",
    "                for age_item in age_of_onset_list:\n",
    "                    age_of_onset_data.append({\n",
    "                        'OrphaCode': orpha_code,\n",
    "                        'DiseaseName': disease_name,\n",
    "                        'AverageAgeOfOnset': age_item.get('AverageAgeOfOnset', '')\n",
    "                    })\n",
    "\n",
    "        age_of_onset_df = pd.DataFrame(age_of_onset_data)\n",
    "        logger.info(f\"Extracted {len(age_of_onset_df)} age of onset entries\")\n",
    "        return age_of_onset_df\n",
    "\n",
    "    def parse_types_of_inheritance(self) -> pd.DataFrame:\n",
    "        if self.data_df is None:\n",
    "          raise ValueError(\"Data not loaded.  Call load_data() first.\")\n",
    "\n",
    "        logger.info(\"Parsing types of inheritance\")\n",
    "        inheritance_data = []\n",
    "\n",
    "        for idx, row in self.data_df.iterrows():\n",
    "            orpha_code = row['OrphaCode']\n",
    "            disease_name = row['Name']\n",
    "            for col_num in range(4, 6):  # Columns df4 and df5\n",
    "                col_name = f'TypesOfInheritance_df{col_num}'\n",
    "                # Use .get() to handle missing columns gracefully.\n",
    "                inheritance_list = self._safe_json_loads(row.get(col_name, '[]'))\n",
    "                if inheritance_list is None:\n",
    "                    continue\n",
    "\n",
    "                for inheritance_item in inheritance_list:\n",
    "                    inheritance_data.append({\n",
    "                        'OrphaCode': orpha_code,\n",
    "                        'DiseaseName': disease_name,\n",
    "                        'TypeOfInheritance': inheritance_item.get('TypeOfInheritance', '')\n",
    "                    })\n",
    "        inheritance_df = pd.DataFrame(inheritance_data)\n",
    "        logger.info(f\"Extracted {len(inheritance_df)} inheritance entries\")\n",
    "        return inheritance_df\n",
    "      \n",
    "    def parse_prevalence_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Parses prevalence data from the PrevalenceData_df5 column.\"\"\"\n",
    "        if self.data_df is None:\n",
    "            raise ValueError(\"Data not loaded. Call load_data() first.\")\n",
    "\n",
    "        logger.info(\"Parsing prevalence data\")\n",
    "        prevalence_data = []\n",
    "\n",
    "        for idx, row in self.data_df.iterrows():\n",
    "            orpha_code = row['OrphaCode']\n",
    "            disease_name = row['Name']\n",
    "            # Use .get() with a default empty string to handle missing columns\n",
    "            prevalence_list = self._safe_json_loads(row.get('PrevalenceData_df5', '[]'))\n",
    "            if prevalence_list is None:\n",
    "                continue\n",
    "\n",
    "            for prev_item in prevalence_list:\n",
    "                prevalence_data.append({\n",
    "                    'OrphaCode': orpha_code,\n",
    "                    'DiseaseName': disease_name,\n",
    "                    'PrevalenceType': prev_item.get('PrevalenceType', ''),\n",
    "                    'PrevalenceQualification': prev_item.get('PrevalenceQualification', ''),\n",
    "                    'PrevalenceClass': prev_item.get('PrevalenceClass', ''),\n",
    "                    'ValMoy': float(prev_item.get('ValMoy', 0.0)),  # Convert to float\n",
    "                    'PrevalenceGeographic': prev_item.get('PrevalenceGeographic', ''),\n",
    "                    'PrevalenceValidationStatus': prev_item.get('PrevalenceValidationStatus', '')\n",
    "                })\n",
    "\n",
    "        prevalence_df = pd.DataFrame(prevalence_data)\n",
    "        logger.info(f\"Extracted {len(prevalence_df)} prevalence entries\")\n",
    "        return prevalence_df\n",
    "\n",
    "    def get_summary_information(self) -> pd.DataFrame:\n",
    "      if self.data_df is None:\n",
    "          raise ValueError(\"Data not loaded. Call load_data() first.\")\n",
    "\n",
    "      logger.info(\"Extracting summary information\")\n",
    "      summary_data = []\n",
    "      for idx, row in self.data_df.iterrows():\n",
    "        orpha_code = row['OrphaCode']\n",
    "        disease_name = row['Name']\n",
    "        #Use .get to handle potential missing\n",
    "        summary_info = self._safe_json_loads(row.get('SummaryInformation_df1','{}'))\n",
    "        if summary_info is None:\n",
    "          continue\n",
    "\n",
    "        definition = summary_info.get('Definition', '')\n",
    "        definition = definition.replace('<i>', '').replace('</i>', '')  # Clean HTML\n",
    "\n",
    "        summary_data.append({\n",
    "            'OrphaCode': orpha_code,\n",
    "            'DiseaseName': disease_name,\n",
    "            'Definition': definition\n",
    "        })\n",
    "\n",
    "      summary_df = pd.DataFrame(summary_data)\n",
    "      logger.info(f\"Extracted {len(summary_df)} disease summaries\")\n",
    "      return summary_df\n",
    "\n",
    "    def _extract_prevalence_value(self, prevalence_class: str) -> float:\n",
    "      \"\"\"Extracts a numerical prevalence value from the PrevalenceClass string.\"\"\"\n",
    "      #Handles prevalence strings, like '<1 / 1 000 000'  or '1-9 / 10 000'\n",
    "      if prevalence_class == 'Unknown' or  prevalence_class == 'N/A':\n",
    "        return 0.0\n",
    "      parts = prevalence_class.split('/')\n",
    "      if len(parts) != 2:\n",
    "        logger.warning(f\"Could not parse prevalence string: {prevalence_class}\") #LOG THE STRING!\n",
    "        return 0.0  # Handle malformed strings\n",
    "      try:\n",
    "        numerator_str = parts[0].strip()\n",
    "        denominator_str = parts[1].strip().replace(' ', '') # Remove spaces in denominator\n",
    "\n",
    "        # Handle ranges in numerator\n",
    "        if '-' in numerator_str:\n",
    "            numerator_range = [float(x) for x in numerator_str.split('-')]\n",
    "            numerator = sum(numerator_range) / len(numerator_range) # Average the range\n",
    "        else:\n",
    "            numerator = float(numerator_str)\n",
    "\n",
    "        denominator = float(denominator_str)\n",
    "        return numerator/denominator\n",
    "      except ValueError:\n",
    "        logger.warning(f'Couldnt extract a value from: {prevalence_class}')\n",
    "        return 0.0 # Handle parsing errors\n",
    "\n",
    "    def prepare_data_for_ml(self) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "      \"\"\"Prepares the final dataset for machine learning.\"\"\"\n",
    "      logger.info(\"Preparing final dataset for machine learning\")\n",
    "\n",
    "      # Get HPO features\n",
    "      if self.hpo_features is None:\n",
    "          self.create_hpo_feature_matrix()\n",
    "\n",
    "      # Create disability features (pivot as needed)\n",
    "      disability_df = self.parse_disability_associations()\n",
    "      if not disability_df.empty:\n",
    "          # Ensure OrphaCode is string type BEFORE pivoting\n",
    "          disability_df['OrphaCode'] = disability_df['OrphaCode'].astype(str)\n",
    "          self.disability_features = disability_df.pivot_table(\n",
    "              index='OrphaCode',\n",
    "              columns='Disability',\n",
    "              values='FrequencyDisabilityValue',\n",
    "              fill_value=0\n",
    "          ).reset_index()\n",
    "\n",
    "      # Create age of onset features (pivot as needed)\n",
    "      age_of_onset_df = self.parse_average_age_of_onset()\n",
    "      if not age_of_onset_df.empty:\n",
    "          # Ensure OrphaCode is string type BEFORE pivoting\n",
    "          age_of_onset_df['OrphaCode'] = age_of_onset_df['OrphaCode'].astype(str)\n",
    "          self.age_of_onset_features = age_of_onset_df.pivot_table(\n",
    "              index='OrphaCode',\n",
    "              columns='AverageAgeOfOnset',\n",
    "              values = 'DiseaseName', #dummy value\n",
    "              aggfunc = 'first', #Presence/absence\n",
    "              fill_value=0\n",
    "            ).reset_index()\n",
    "\n",
    "\n",
    "      # Create inheritance features\n",
    "      inheritance_df = self.parse_types_of_inheritance()\n",
    "      if not inheritance_df.empty:\n",
    "          # Ensure OrphaCode is string type BEFORE pivoting\n",
    "          inheritance_df['OrphaCode'] = inheritance_df['OrphaCode'].astype(str)\n",
    "          self.inheritance_features = inheritance_df.pivot_table(\n",
    "              index='OrphaCode',\n",
    "              columns='TypeOfInheritance',\n",
    "              values = 'DiseaseName', #dummy value\n",
    "              aggfunc = 'first',\n",
    "              fill_value = 0\n",
    "          ).reset_index()\n",
    "\n",
    "      # Create prevalence features - keep raw values and class.\n",
    "      prevalence_df = self.parse_prevalence_data()\n",
    "      if not prevalence_df.empty:\n",
    "          # Ensure OrphaCode is string type BEFORE grouping\n",
    "          prevalence_df['OrphaCode'] = prevalence_df['OrphaCode'].astype(str)\n",
    "          # Numerical prevalence.\n",
    "          prevalence_df['PrevalenceValue'] = prevalence_df['PrevalenceClass'].apply(self._extract_prevalence_value)\n",
    "          self.prevalence_features = prevalence_df.groupby('OrphaCode')['PrevalenceValue'].mean().reset_index() # Use mean for now\n",
    "\n",
    "      # --- Merge features, with explicit type handling ---\n",
    "      features = self.hpo_features\n",
    "      # Ensure OrphaCode is consistent type (string) BEFORE merging\n",
    "      features['OrphaCode'] = features['OrphaCode'].astype(str)\n",
    "\n",
    "\n",
    "      if self.disability_features is not None:\n",
    "        features = features.merge(self.disability_features, on='OrphaCode', how='left')\n",
    "\n",
    "      if self.age_of_onset_features is not None:\n",
    "        features = features.merge(self.age_of_onset_features, on='OrphaCode', how='left')\n",
    "\n",
    "      if self.inheritance_features is not None:\n",
    "          features = features.merge(self.inheritance_features, on='OrphaCode', how='left')\n",
    "\n",
    "      if self.prevalence_features is not None:\n",
    "          features = features.merge(self.prevalence_features, on='OrphaCode', how='left')\n",
    "\n",
    "\n",
    "      # Extract target and features\n",
    "      y = features['OrphaCode']\n",
    "      X = features.drop(['OrphaCode', 'DiseaseName'], axis=1, errors='ignore')\n",
    "\n",
    "      # Fill missing values (left after merging)\n",
    "      X = X.fillna(0)\n",
    "\n",
    "      # --- TYPE ENFORCEMENT (BEFORE SCALING/ENCODING) ---\n",
    "      # Identify likely categorical columns (after merging)\n",
    "      likely_categorical = []\n",
    "      for col in X.columns:\n",
    "          if X[col].dtype == 'object':  # If it's already object, it's categorical\n",
    "              likely_categorical.append(col)\n",
    "          elif X[col].nunique() < 20: #If has few values, probably a category\n",
    "              likely_categorical.append(col)\n",
    "\n",
    "\n",
    "      # Enforce string type on these columns\n",
    "      for col in likely_categorical:\n",
    "            X[col] = X[col].astype(str)\n",
    "\n",
    "      # -----------------------------------------------------\n",
    "\n",
    "      # Apply prevalence weighting (example - adjust as needed)\n",
    "      if 'PrevalenceValue' in X.columns:\n",
    "          # Scale prevalence to avoid overwhelming other features\n",
    "          #  Here, we're simply taking the log, but you might want something else.\n",
    "          X['PrevalenceValue'] = np.log1p(X['PrevalenceValue'])\n",
    "      logger.info(f\"Final dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "      return X, y\n",
    "\n",
    "    def save_processed_data(self, output_path: str) -> None:\n",
    "        \"\"\"Save processed data to CSV file.\"\"\"\n",
    "        if self.hpo_features is None:\n",
    "            raise ValueError(\"No processed data available.  Process data first.\")\n",
    "\n",
    "        full_path = os.path.join(self.data_dir, output_path)\n",
    "        logger.info(f\"Saving processed data to {full_path}\")\n",
    "\n",
    "        X, y = self.prepare_data_for_ml()\n",
    "        output_df = X.copy()\n",
    "        output_df['OrphaCode'] = y  # Add target back\n",
    "        output_df.to_csv(full_path, index=False)\n",
    "        logger.info(f\"Saved processed data with {output_df.shape[1]} columns\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "Feature Engineering Module for Rare Disease Prediction System.\n",
    "\n",
    "This module handles feature transformation, selection, and encoding for\n",
    "the rare disease prediction models.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import Tuple, List, Dict, Union, Optional\n",
    "import logging\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FeatureEngineer:\n",
    "    \"\"\"\n",
    "    Class for advanced feature engineering operations on Orphanet data.\n",
    "\n",
    "    This class handles feature scaling, selection, dimensionality reduction,\n",
    "    and encoding for improving model performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models_dir: str = \"../models\"):\n",
    "        \"\"\"\n",
    "        Initialize the FeatureEngineer.\n",
    "\n",
    "        Args:\n",
    "            models_dir: Directory where preprocessing models will be stored\n",
    "        \"\"\"\n",
    "        self.models_dir = models_dir\n",
    "        self.scaler = None\n",
    "        self.feature_selector = None\n",
    "        self.pca = None\n",
    "        self.encoders = {}\n",
    "        self.numerical_columns = []\n",
    "        self.categorical_columns = []\n",
    "        self.selected_features = []\n",
    "\n",
    "        # Create models directory if it doesn't exist\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    def identify_feature_types(self, X: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Identify numerical and categorical features in the dataset.\n",
    "\n",
    "        Args:\n",
    "            X: Feature DataFrame\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (numerical column names, categorical column names)\n",
    "        \"\"\"\n",
    "        logger.info(\"Identifying feature types\")\n",
    "\n",
    "        numerical_cols = []\n",
    "        categorical_cols = []\n",
    "\n",
    "        for col in X.columns:\n",
    "            # Check if the column has numeric data\n",
    "            if X[col].dtype in ['int64', 'float64']:\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                categorical_cols.append(col)\n",
    "\n",
    "        self.numerical_columns = numerical_cols\n",
    "        self.categorical_columns = categorical_cols\n",
    "\n",
    "        logger.info(f\"Identified {len(numerical_cols)} numerical and {len(categorical_cols)} categorical features\")\n",
    "        return numerical_cols, categorical_cols\n",
    "\n",
    "    def handle_missing_values(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Handle missing values in the dataset.\n",
    "\n",
    "        Args:\n",
    "            X: Feature DataFrame\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with missing values handled\n",
    "        \"\"\"\n",
    "        logger.info(\"Handling missing values\")\n",
    "\n",
    "        # For HPO features (numerical), fill NaN with 0 (absence of symptom)\n",
    "        # For categorical features, fill with most frequent value\n",
    "\n",
    "        # Identify feature types if not already done\n",
    "        if not self.numerical_columns and not self.categorical_columns:\n",
    "            self.identify_feature_types(X)\n",
    "\n",
    "        # Handle numerical features\n",
    "        X_num = X[self.numerical_columns].fillna(0)\n",
    "\n",
    "        # Handle categorical features\n",
    "        X_cat = X[self.categorical_columns].copy()\n",
    "        if not X_cat.empty:\n",
    "            for col in X_cat.columns:\n",
    "                X_cat[col] = X_cat[col].fillna(X_cat[col].mode()[0] if not X_cat[col].mode().empty else \"UNKNOWN\")\n",
    "\n",
    "        # Combine processed features\n",
    "        X_processed = pd.concat([X_num, X_cat], axis=1)\n",
    "\n",
    "        logger.info(f\"Handled missing values in {X.shape[1]} features\")\n",
    "        return X_processed\n",
    "\n",
    "\n",
    "    def scale_features(self, X: pd.DataFrame, fit: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Scale numerical features.\n",
    "\n",
    "        Args:\n",
    "            X: Feature DataFrame\n",
    "            fit: Whether to fit the scaler on this data\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with scaled features\n",
    "        \"\"\"\n",
    "        logger.info(\"Scaling numerical features\")\n",
    "\n",
    "        # Identify feature types if not already done\n",
    "        if not self.numerical_columns and not self.categorical_columns:\n",
    "            self.identify_feature_types(X)\n",
    "\n",
    "        # --- ADDED CHECK FOR EMPTY NUMERICAL COLUMNS ---\n",
    "        if not self.numerical_columns:\n",
    "            logger.info(\"No numerical features to scale. Returning original DataFrame.\")\n",
    "            return X.copy()  # Return the input unchanged (but as a copy!)\n",
    "        # -----------------------------------------------\n",
    "\n",
    "        # Get numerical columns\n",
    "        X_num = X[self.numerical_columns].copy()\n",
    "\n",
    "        # Create and fit scaler if needed\n",
    "        if fit or self.scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            X_num_scaled = pd.DataFrame(\n",
    "                self.scaler.fit_transform(X_num),\n",
    "                columns=X_num.columns,\n",
    "                index=X_num.index\n",
    "            )\n",
    "        else:\n",
    "            X_num_scaled = pd.DataFrame(\n",
    "                self.scaler.transform(X_num),\n",
    "                columns=X_num.columns,\n",
    "                index=X_num.index\n",
    "            )\n",
    "\n",
    "        # Combine with categorical features\n",
    "        X_cat = X[self.categorical_columns].copy() if self.categorical_columns else pd.DataFrame(index=X.index)\n",
    "        X_scaled = pd.concat([X_num_scaled, X_cat], axis=1)\n",
    "\n",
    "        logger.info(f\"Scaled {len(self.numerical_columns)} numerical features\")\n",
    "        return X_scaled\n",
    "\n",
    "    def encode_categorical_features(self, X: pd.DataFrame, fit: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Encode categorical features using one-hot encoding.\n",
    "\n",
    "        Args:\n",
    "            X: Feature DataFrame\n",
    "            fit: Whether to fit the encoders on this data\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with encoded features\n",
    "        \"\"\"\n",
    "        logger.info(\"Encoding categorical features\")\n",
    "\n",
    "        # Identify feature types if not already done\n",
    "        if not self.numerical_columns and not self.categorical_columns:\n",
    "            self.identify_feature_types(X)\n",
    "\n",
    "        # No categorical features to encode\n",
    "        if not self.categorical_columns:\n",
    "            logger.info(\"No categorical features to encode\")\n",
    "            return X\n",
    "\n",
    "        # Get numerical features\n",
    "        X_num = X[self.numerical_columns].copy()\n",
    "\n",
    "        # Initialize list to store encoded DataFrames\n",
    "        encoded_dfs = [X_num]\n",
    "\n",
    "        # Encode each categorical feature\n",
    "        for col in self.categorical_columns:\n",
    "            # Handle potential NaN values\n",
    "            X[col] = X[col].fillna('UNKNOWN')\n",
    "\n",
    "            # Create encoder if needed\n",
    "            if fit or col not in self.encoders:\n",
    "                encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "                encoded_data = encoder.fit_transform(X[[col]])\n",
    "                self.encoders[col] = encoder\n",
    "            else:\n",
    "                encoder = self.encoders[col]\n",
    "                encoded_data = encoder.transform(X[[col]])\n",
    "\n",
    "            # Create DataFrame with encoded data\n",
    "            encoded_df = pd.DataFrame(\n",
    "                encoded_data,\n",
    "                columns=[f\"{col}_{val}\" for val in encoder.categories_[0]],\n",
    "                index=X.index\n",
    "            )\n",
    "\n",
    "            # Add to list of encoded DataFrames\n",
    "            encoded_dfs.append(encoded_df)\n",
    "\n",
    "        # Combine all encoded features\n",
    "        X_encoded = pd.concat(encoded_dfs, axis=1)\n",
    "\n",
    "        logger.info(f\"Encoded {len(self.categorical_columns)} categorical features\")\n",
    "        return X_encoded\n",
    "\n",
    "    def select_features(self, X: pd.DataFrame, y: pd.Series, n_features: int = 100, method: str = 'mi', fit: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Select top features using statistical methods.\n",
    "\n",
    "        Args:\n",
    "            X: Feature DataFrame\n",
    "            y: Target variable\n",
    "            n_features: Number of features to select\n",
    "            method: Feature selection method ('mi' for mutual info, 'chi2' for chi-squared)\n",
    "            fit: Whether to fit the selector on this data\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with selected features\n",
    "        \"\"\"\n",
    "        logger.info(f\"Selecting top {n_features} features using {method}\")\n",
    "\n",
    "        # Adjust n_features if it exceeds available features\n",
    "        n_features = min(n_features, X.shape[1])\n",
    "\n",
    "    def select_features(self, X: pd.DataFrame, y: pd.Series, n_features: int = 100, method: str = 'mi', fit: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Select top features using statistical methods.\n",
    "\n",
    "        Args:\n",
    "            X: Feature DataFrame\n",
    "            y: Target variable\n",
    "            n_features: Number of features to select\n",
    "            method: Feature selection method ('mi' for mutual info, 'chi2' for chi-squared)\n",
    "            fit: Whether to fit the selector on this data\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with selected features\n",
    "        \"\"\"\n",
    "        logger.info(f\"Selecting top {n_features} features using {method}\")\n",
    "\n",
    "        # Adjust n_features if it exceeds available features\n",
    "        n_features = min(n_features, X.shape[1])\n",
    "\n",
    "        # --- EMPTY DATAFRAME CHECK ---\n",
    "        if X.empty or X.shape[0] == 0 or X.shape[1] == 0:  # Check for empty DataFrame OR if 0 columns\n",
    "            logger.warning(\"Empty DataFrame passed to select_features or DataFrame with 0 columns. Returning empty DataFrame with n_features columns.\")\n",
    "            return pd.DataFrame(columns=[f\"feature_{i}\" for i in range(n_features)])  # Return empty DataFrame\n",
    "        # -----------------------------\n",
    "\n",
    "\n",
    "        # Create feature selector if needed\n",
    "        if fit or self.feature_selector is None:\n",
    "            if method == 'mi':\n",
    "                 # --- FORCE CONTINUOUS FEATURES ---\n",
    "                self.feature_selector = SelectKBest(lambda X, y: mutual_info_classif(X, y, discrete_features=False), k=n_features)\n",
    "                # ------------------------------------\n",
    "            elif method == 'chi2':\n",
    "                # Ensure all features are non-negative for chi2\n",
    "                X_non_neg = X.copy()\n",
    "                for col in X.columns:\n",
    "                    if X_non_neg[col].min() < 0:\n",
    "                        X_non_neg[col] = X_non_neg[col] - X_non_neg[col].min()\n",
    "                self.feature_selector = SelectKBest(chi2, k=n_features)\n",
    "                X = X_non_neg  # Use the non-negative version for chi2\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature selection method: {method}\")\n",
    "\n",
    "            # Fit and transform\n",
    "            # Check if y has samples. If not, return empty DataFrame with appropriate columns.\n",
    "            if len(y) == 0:\n",
    "                return pd.DataFrame(columns=[f\"feature_{i}\" for i in range(n_features)]) # Return DF with correct number of columns\n",
    "            X_selected = self.feature_selector.fit_transform(X, y)\n",
    "\n",
    "            # Get selected feature names\n",
    "            selected_mask = self.feature_selector.get_support()\n",
    "            self.selected_features = X.columns[selected_mask].tolist()\n",
    "        else:\n",
    "            # Transform using existing selector\n",
    "            X_selected = self.feature_selector.transform(X)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        X_selected_df = pd.DataFrame(\n",
    "            X_selected,\n",
    "            columns=self.selected_features,\n",
    "            index=X.index  # Keep the original index\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Selected {len(self.selected_features)} features\")\n",
    "        return X_selected_df\n",
    "\n",
    "    def reduce_dimensions(self, X: pd.DataFrame, n_components: int = 50, fit: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Reduce dimensions using PCA.\n",
    "\n",
    "        Args:\n",
    "            X: Feature DataFrame\n",
    "            n_components: Number of PCA components\n",
    "            fit: Whether to fit PCA on this data\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with reduced dimensions\n",
    "        \"\"\"\n",
    "        logger.info(f\"Reducing dimensions to {n_components} components\")\n",
    "\n",
    "        # --- ADDED EMPTY/SINGLE-COLUMN CHECK ---\n",
    "        if X.empty or X.shape[1] <= 1:  # Check for empty or single-column DataFrame\n",
    "            logger.warning(\"Empty DataFrame or only one column in reduce_dimensions. Returning original DataFrame (no PCA).\")\n",
    "            return X.copy()  # Return a copy to avoid modifying the original\n",
    "        # ---------------------------------------\n",
    "\n",
    "        # Adjust n_components if it exceeds available features\n",
    "        n_components = min(n_components, X.shape[1])\n",
    "\n",
    "        # Create and fit PCA if needed\n",
    "        if fit or self.pca is None:\n",
    "            self.pca = PCA(n_components=n_components)\n",
    "            X_pca = self.pca.fit_transform(X)\n",
    "        else:\n",
    "            X_pca = self.pca.transform(X)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        X_pca_df = pd.DataFrame(\n",
    "            X_pca,\n",
    "            columns=[f\"PC{i+1}\" for i in range(n_components)],\n",
    "            index=X.index\n",
    "        )\n",
    "\n",
    "        # Log explained variance\n",
    "        if fit or self.pca is None:\n",
    "            explained_var = self.pca.explained_variance_ratio_.sum()\n",
    "            logger.info(f\"PCA explains {explained_var:.2%} of variance with {n_components} components\")\n",
    "\n",
    "        return X_pca_df\n",
    "\n",
    "    def create_feature_pipeline(self, X: pd.DataFrame, y: pd.Series, use_pca: bool = True,\n",
    "                              n_features: int = 100, n_components: int = 50) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply the full feature engineering pipeline.\n",
    "\n",
    "        Args:\n",
    "            X: Raw feature DataFrame\n",
    "            y: Target variable\n",
    "            use_pca: Whether to use PCA dimensionality reduction\n",
    "            n_features: Number of features to select\n",
    "            n_components: Number of PCA components (if use_pca is True)\n",
    "\n",
    "        Returns:\n",
    "            Fully processed feature DataFrame\n",
    "        \"\"\"\n",
    "        logger.info(\"Applying full feature engineering pipeline\")\n",
    "\n",
    "        # Identify feature types\n",
    "        self.identify_feature_types(X)\n",
    "\n",
    "        # Handle missing values\n",
    "        X_processed = self.handle_missing_values(X)\n",
    "\n",
    "        # Scale features\n",
    "        X_scaled = self.scale_features(X_processed, fit=True)\n",
    "\n",
    "        # Encode categorical features\n",
    "        X_encoded = self.encode_categorical_features(X_scaled, fit=True)\n",
    "\n",
    "        # --- ADDED EMPTY DATAFRAME CHECK AFTER ENCODING ---\n",
    "        if X_encoded.shape[0] == 0:\n",
    "            logger.warning(\"Empty DataFrame after encoding. Returning empty DataFrame.\")\n",
    "            return pd.DataFrame()  # Or return X_encoded, since it's already empty\n",
    "        # ----------------------------------------------------\n",
    "\n",
    "        # Select features\n",
    "        X_selected = self.select_features(X_encoded, y, n_features=n_features, fit=True)\n",
    "\n",
    "        # Reduce dimensions if requested\n",
    "        if use_pca:\n",
    "            X_final = self.reduce_dimensions(X_selected, n_components=n_components, fit=True)\n",
    "        else:\n",
    "            X_final = X_selected\n",
    "\n",
    "        logger.info(f\"Feature pipeline complete: {X.shape} -> {X_final.shape}\")\n",
    "        return X_final\n",
    "\n",
    "    def transform_features(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform new data using the existing pipeline.\n",
    "\n",
    "        Args:\n",
    "            X: Raw feature DataFrame\n",
    "\n",
    "        Returns:\n",
    "            Processed feature DataFrame\n",
    "        \"\"\"\n",
    "        if self.scaler is None:\n",
    "            raise ValueError(\"Feature pipeline not initialized. Call create_feature_pipeline() first.\")\n",
    "\n",
    "        # Handle missing values\n",
    "        X_processed = self.handle_missing_values(X)\n",
    "\n",
    "        # Scale features\n",
    "        X_scaled = self.scale_features(X_processed, fit=False)\n",
    "\n",
    "        # Encode categorical features\n",
    "        X_encoded = self.encode_categorical_features(X_scaled, fit=False)\n",
    "\n",
    "        # Select features\n",
    "        if self.feature_selector is not None:\n",
    "            # Check if all selected features are present\n",
    "            missing_cols = set(self.selected_features) - set(X_encoded.columns)\n",
    "            for col in missing_cols:\n",
    "                X_encoded[col] = 0  # Add missing columns with default values\n",
    "\n",
    "            # Select only the columns needed for the feature selector\n",
    "            X_selected = X_encoded[self.selected_features]\n",
    "        else:\n",
    "            X_selected = X_encoded\n",
    "\n",
    "        # Reduce dimensions if PCA was used\n",
    "        if self.pca is not None:\n",
    "            X_final = self.reduce_dimensions(X_selected, fit=False)\n",
    "        else:\n",
    "            X_final = X_selected\n",
    "\n",
    "        return X_final\n",
    "\n",
    "    def save_pipeline(self, filename: str = \"feature_pipeline\") -> None:\n",
    "        \"\"\"\n",
    "        Save the feature engineering pipeline objects.\n",
    "\n",
    "        Args:\n",
    "            filename: Base filename for saved objects\n",
    "        \"\"\"\n",
    "        logger.info(f\"Saving feature engineering pipeline to {self.models_dir}\")\n",
    "\n",
    "        # Create dictionary of objects to save\n",
    "        pipeline_objects = {\n",
    "            'scaler': self.scaler,\n",
    "            'feature_selector': self.feature_selector,\n",
    "            'pca': self.pca,\n",
    "            'encoders': self.encoders,\n",
    "            'selected_features': self.selected_features,\n",
    "            'numerical_columns': self.numerical_columns,\n",
    "            'categorical_columns': self.categorical_columns\n",
    "        }\n",
    "\n",
    "        # Save each object individually\n",
    "        for key, value in pipeline_objects.items():\n",
    "            joblib.dump(value, os.path.join(self.models_dir, f\"{filename}_{key}.joblib\"))\n",
    "\n",
    "        logger.info(\"Feature engineering pipeline saved successfully.\")\n",
    "\n",
    "\n",
    "    def load_pipeline(self, filename: str = \"feature_pipeline\") -> None:\n",
    "        \"\"\"\n",
    "        Load the feature engineering pipeline objects.\n",
    "\n",
    "        Args:\n",
    "            filename: Base filename for saved objects.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Loading feature engineering pipeline from {self.models_dir}\")\n",
    "\n",
    "        try:\n",
    "            self.scaler = joblib.load(os.path.join(self.models_dir, f\"{filename}_scaler.joblib\"))\n",
    "            self.feature_selector = joblib.load(os.path.join(self.models_dir, f\"{filename}_feature_selector.joblib\"))\n",
    "            self.pca = joblib.load(os.path.join(self.models_dir, f\"{filename}_pca.joblib\"))\n",
    "            self.encoders = joblib.load(os.path.join(self.models_dir, f\"{filename}_encoders.joblib\"))\n",
    "            self.selected_features = joblib.load(os.path.join(self.models_dir, f\"{filename}_selected_features.joblib\"))\n",
    "            self.numerical_columns = joblib.load(os.path.join(self.models_dir, f\"{filename}_numerical_columns.joblib\"))\n",
    "            self.categorical_columns = joblib.load(os.path.join(self.models_dir, f\"{filename}_categorical_columns.joblib\"))\n",
    "            logger.info(\"Feature engineering pipeline loaded successfully.\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            logger.error(f\"Error loading pipeline: {e}.  Make sure the pipeline has been saved.\")\n",
    "            raise  # Re-raise the exception to halt execution if critical components are missing.\n",
    "\n",
    "            \n",
    "            \n",
    "  \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "   \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8_giEP2ac-Tr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 19:45:15,640 - __main__ - INFO - Loading data from ../data/sample_debug_orphanet_data.csv\n",
      "2025-02-26 19:45:15,643 - __main__ - INFO - Loaded 2 records\n",
      "2025-02-26 19:45:15,643 - __main__ - INFO - Preparing final dataset for machine learning\n",
      "2025-02-26 19:45:15,643 - __main__ - INFO - Parsing HPO associations\n",
      "2025-02-26 19:45:15,644 - __main__ - INFO - Extracted 40 HPO associations\n",
      "2025-02-26 19:45:15,644 - __main__ - INFO - Creating HPO feature matrix\n",
      "2025-02-26 19:45:15,648 - __main__ - INFO - Created feature matrix with 36 HPO features\n",
      "2025-02-26 19:45:15,648 - __main__ - INFO - Parsing disability associations\n",
      "2025-02-26 19:45:15,649 - __main__ - WARNING - Invalid JSON encountered: nan, error: the JSON object must be str, bytes or bytearray, not float\n",
      "2025-02-26 19:45:15,649 - __main__ - WARNING - Invalid JSON encountered: nan, error: the JSON object must be str, bytes or bytearray, not float\n",
      "2025-02-26 19:45:15,649 - __main__ - WARNING - Invalid JSON encountered: nan, error: the JSON object must be str, bytes or bytearray, not float\n",
      "2025-02-26 19:45:15,649 - __main__ - WARNING - Invalid JSON encountered: nan, error: the JSON object must be str, bytes or bytearray, not float\n",
      "2025-02-26 19:45:15,649 - __main__ - WARNING - Invalid JSON encountered: nan, error: the JSON object must be str, bytes or bytearray, not float\n",
      "2025-02-26 19:45:15,650 - __main__ - WARNING - Invalid JSON encountered: nan, error: the JSON object must be str, bytes or bytearray, not float\n",
      "2025-02-26 19:45:15,650 - __main__ - INFO - Extracted 0 disability associations\n",
      "2025-02-26 19:45:15,650 - __main__ - INFO - Parsing average age of onset\n",
      "2025-02-26 19:45:15,651 - __main__ - INFO - Extracted 0 age of onset entries\n",
      "2025-02-26 19:45:15,651 - __main__ - INFO - Parsing types of inheritance\n",
      "2025-02-26 19:45:15,652 - __main__ - INFO - Extracted 0 inheritance entries\n",
      "2025-02-26 19:45:15,652 - __main__ - INFO - Parsing prevalence data\n",
      "2025-02-26 19:45:15,653 - __main__ - INFO - Extracted 0 prevalence entries\n",
      "2025-02-26 19:45:15,659 - __main__ - INFO - Final dataset: 2 samples, 36 features\n",
      "2025-02-26 19:45:15,659 - __main__ - INFO - Applying full feature engineering pipeline\n",
      "2025-02-26 19:45:15,660 - __main__ - INFO - Identifying feature types\n",
      "2025-02-26 19:45:15,660 - __main__ - INFO - Identified 0 numerical and 36 categorical features\n",
      "2025-02-26 19:45:15,661 - __main__ - INFO - Handling missing values\n",
      "2025-02-26 19:45:15,672 - __main__ - INFO - Handled missing values in 36 features\n",
      "2025-02-26 19:45:15,672 - __main__ - INFO - Scaling numerical features\n",
      "2025-02-26 19:45:15,673 - __main__ - INFO - No numerical features to scale. Returning original DataFrame.\n",
      "2025-02-26 19:45:15,673 - __main__ - INFO - Encoding categorical features\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "2025-02-26 19:45:15,724 - __main__ - INFO - Encoded 36 categorical features\n",
      "2025-02-26 19:45:15,725 - __main__ - INFO - Selecting top 10 features using mi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2370256/3052700220.py\", line 15, in <module>\n",
      "    X_transformed = feature_engineer.create_feature_pipeline(X, y, use_pca=True, n_features=10, n_components=5)\n",
      "  File \"/tmp/ipykernel_2370256/1379365356.py\", line 804, in create_feature_pipeline\n",
      "    X_selected = self.select_features(X_encoded, y, n_features=n_features, fit=True)\n",
      "  File \"/tmp/ipykernel_2370256/1379365356.py\", line 705, in select_features\n",
      "    X_selected = self.feature_selector.fit_transform(X, y)\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/base.py\", line 851, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 472, in fit\n",
      "    score_func_ret = self.score_func(X, y)\n",
      "  File \"/tmp/ipykernel_2370256/1379365356.py\", line 688, in <lambda>\n",
      "    self.feature_selector = SelectKBest(lambda X, y: mutual_info_classif(X, y, discrete_features=False), k=n_features)\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py\", line 468, in mutual_info_classif\n",
      "    return _estimate_mi(X, y, discrete_features, True, n_neighbors, copy, random_state)\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py\", line 304, in _estimate_mi\n",
      "    mi = [\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py\", line 305, in <listcomp>\n",
      "    _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py\", line 163, in _compute_mi\n",
      "    return _compute_mi_cd(x, y, n_neighbors)\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py\", line 138, in _compute_mi_cd\n",
      "    kd = KDTree(c)\n",
      "  File \"sklearn/neighbors/_binary_tree.pxi\", line 833, in sklearn.neighbors._kd_tree.BinaryTree.__init__\n",
      "  File \"/home/anat/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 929, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize and load data\n",
    "    data_processor = OrphanetDataProcessor(data_dir='../data')  # Use local directory\n",
    "    data_processor.load_data(\"sample_debug_orphanet_data.csv\")\n",
    "\n",
    "    # Prepare data for ML (includes parsing and initial feature matrix creation)\n",
    "    X, y = data_processor.prepare_data_for_ml()\n",
    "\n",
    "    # Ensure y is a string BEFORE feature engineering\n",
    "    y = y.astype(str)\n",
    "    # Initialize FeatureEngineer\n",
    "    feature_engineer = FeatureEngineer(models_dir=\"./\")\n",
    "\n",
    "    # Create the feature engineering pipeline\n",
    "    X_transformed = feature_engineer.create_feature_pipeline(X, y, use_pca=True, n_features=10, n_components=5)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    breakpoint() # !important\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OLEOHlobdVG8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'OrphanetDataProcessor' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2353377/3052700220.py\", line 3, in <module>\n",
      "    data_processor = OrphanetDataProcessor(data_dir='../data')  # Use local directory\n",
      "NameError: name 'OrphanetDataProcessor' is not defined\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lO0v0iDTdVVN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
